\documentclass[../main.tex]{subfiles}

\begin{document}

\chapter{linear algebra}

${ add_statement(

'Linear Transformation',

r'''
A linear transformation on a @space@ G is a @bijection@ mapping from a @coordinate system@ $ \Lambda $ on G mapping to a @state vector space@ V to a coordinate system $\Psi$ on same G mapping to state vector space W of same dimension as V, such that each @vector@ in @standard basis@ of W is a @linear combination@ of each vector in standard basis of V.
''',

r'''
A simple tool for moving b/w representations of space.
Some popular examples of linear transformations are rotation, scale, sheer.

For instance in a 2D state vector space, if standard basis of W say $ \hat{o}, \hat{p} $ are linear combinations of standard basis of V say $ \hat{d}, \hat{f} $ as follows
\[  \hat{o} = 3 * \hat{d} + 2 * \hat{f} \]
\[  \hat{p} = 0 * \hat{d} + 2 * \hat{f} \]
Note that
\begin{enumerate}[nolistsep]
  \item In V $ \hat{o}, \hat{p} $ represent $ \begin{bmatrix} 1 \\ 0 \end{bmatrix} and \begin{bmatrix} 0 \\ 1 \end{bmatrix} $ repsectively.
  \item In W $ \hat{d}, \hat{f} $ represent $ \begin{bmatrix} 1 \\ 0 \end{bmatrix} and \begin{bmatrix} 0 \\ 1 \end{bmatrix} $ repsectively.
\end{enumerate}
But V and W are different representations of the same space. Therfore,
\begin{enumerate}[nolistsep]
  \item $ \hat{o} $ represents a same vector as $ \hat{d} $. So they are indentical in this context.
  \item $ \hat{o} $ represents a different point than $ \hat{d} $. So they are non-identical in this context.
\end{enumerate}
Therefore when we say two vectors are equal we should be careful about the context of the discussion.

Suppose a point $ \eta $ is represented by $ \begin{bmatrix} 4 \\ 10 \end{bmatrix} $ in $ \Psi $.
That means P is represented by $ 4 * \hat{o} + 10 * \hat{p} $.
Now to get representation of the same point $ \eta $ in $ \Lambda $ (remember points do not change with anything) we just substitute the expressions of $ \hat{o}, \hat{p} $ in terms of $ \hat{d}, \hat{f} $ as given above, i.e. $ 4 * (3 * \hat{d} + 2 * \hat{f}) + 10 * (0 * \hat{d} + 2 * \hat{f}) $ which gives $ 12 * \hat{d} + 28 * \hat{f} $.
This can be written as
\[
  4 * \begin{bmatrix} 3 \\ 2 \end{bmatrix} + 10 * \begin{bmatrix} 0 \\ 2 \end{bmatrix}
\]
which can be further packaged as a matrix multiplication.
\[
  \begin{bmatrix} 3 & 0 \\ 2 & 2 \end{bmatrix} \begin{bmatrix} 4 \\ 10 \end{bmatrix}
\]
This is why the matrix multiplication was invented. Mind Blown!!
Therefore columns in a matrix can be seen as the representations of standard basis of new coordinate system in the old one.

Therefore the linear tranform can be seen as a way to do the following things
\begin{enumerate}[nolistsep]
  \item Given a transformed coordinate system i.e. given standard basis of new coordinate system in terms of the old one, we can get the representation for the same point in two different systems.
  \item Visualize moving a vector $ \lambda $ representing a point A in $ \Lambda $ to the point B represented in $ \Psi $ by $ \psi $ which is numerically equal to $ \lambda $.
\end{enumerate}
Donot mix these two.

Misconceptions busting. The following are true statements.
\begin{enumerate}[nolistsep]
  \item Rotation is not a property of a body, it is a property of a pair of coordinate systems. One of the coordinate systems can be attached to a body.
  \item Rotation is not some complicated thing, it is just a linear transformation. The columns of the matrix representing rotation transform are just the places where the new standard basis land in old coordinate system.
  \item There is no such thing as multiplying a vector on its right by a matrix (contrary to left side which we can use for linear transform). Dimensions don't match for multiplication to occur.
  \item Linear transformation is not about raw numbers, the idea comes from visualing space and trying to play with it.
\end{enumerate}


''',

r'''
\proofbydefinition
'''

) }

${ add_statement(

'Rotation Transformation',

r'''
A rotation transformation is a @linear transformation@ on a @space@ G from @coordinate system@ $\Lambda$ with @state vector space@ V to coordinate system $\Psi$ with state vector space W, in which each vector in @standard basis@ of W has @L2 norm@ of 1 and is perpendicular to all others @perpendicular vectors@
''',

r'''
Defines a rotation operation.
The matrix formed by such transformation is called rotation transformation matrix or rotation matrix for short.
The standard basis of W forms an orthonormal basis.

In 3D the number of degrees of freedom for a rotation matrix is 3 even though we have 9 elements in a 3x3 matrix.
This is because for a 3D unit vector we have two degrees of freedom (the third one is fixed when we choose first two due to length constraint).
Therefore by choosing the unit vector value of first axis of new coordinate system in the old coordinate system we used 2 degrees of freedom.
Given this vector we have to choose a perpendicular vector i.e. any vector in plane perpendicular to it.
Choosing this will require 1 degree of freedom which is the angle of vector in that plane.
The final vector is just the cross product of first two which uses 0 degrees of freedom.

Say there is a state vector v.
After a rotation tranformation the same state vector v in new coordinate system is represented by state vector u in old one.
Two vectors form a plane.
So u, v form a plane P that passes through the origin.
Every plane has one and only one normal, P also has one and only one normal n.
The rotation transformation matrix has a determinant $\equiv 1$ because it is a orthonormal matrix.
Therefore the length (L2 norms) of both vectors u, v are identical.
In the plane P we have angle b/w u, v say $\theta$.
Therefore the whole rotation transformation can be seen as a rotating the state vector v about one and only one axis n by angle $\theta$ to reach u.
There you have the good old way to thinking about rotation. Mind blown!!

Misconceptions busting. The following are true statements.
\begin{enumerate}[nolistsep]
  \item Rotation is not a property of a body, it is a property of a pair of coordinate systems. One of the coordinate systems can be attached to a body.
  \item Rotation is no some complicated thing, it is just a linear transformation. The columns of the matrix representing rotation transform are just the places where the new standard basis land in old coordinate system.
  \item In 3D, every rotation always has one and only one axis of rotation which passes through origin. Rotation about an axis not passing through origin is not defined.
  \item Similarly, in 2D, every rotation is always about origin. Rotation about a point which is not an origin is not defined.
  \item Although rotation is a linear transform, the result of rotation may not be linear in terms of the angle of rotation.
  \[
    \begin{bmatrix}
        a \\
        b
    \end{bmatrix}
    \equiv
    \begin{bmatrix}
        c\theta & -s\theta \\
        s\theta & c\theta
    \end{bmatrix}
    *
    \begin{bmatrix}
        x \\
        y
    \end{bmatrix}
  \]
  \[
    \begin{bmatrix}
        a \\
        b
    \end{bmatrix}
    \equiv
    \begin{bmatrix}
        xc\theta - ys\theta \\
        xs\theta + yc\theta
    \end{bmatrix}
  \]
  For example here the result $[a, b]^T$ is linear in terms of $c\theta, s\theta$ and not $\theta$ even though entire rotation matrix can be generated only using $\theta$.
  A bit misleading indeed.
\end{enumerate}

''',

r'''
\proofbydefinition
'''

) }


${ add_statement(

'Definiteness',

r'''
Let a square matrix M represent a @linear transformation@ on a @space@ G. If
\begin{enumerate}[nolistsep]
  \item $z^TMz > 0$ for any non-zero vector $z \biimpl$ it (transformation) is called positive definite.
  \item $z^TMz < 0$ for any non-zero vector $z \biimpl$ it is called negative definite.
  \item $z^TMz \ge 0$ for any non-zero vector $z \biimpl$ it is called postive semi-definite.
  \item $z^TMz \le 0$ for any non-zero vector $z \biimpl$ it is called negative semi-definite.
  \item else it is called indefinite.
\end{enumerate}
''',

r'''
A neat way to classify transformations.
In the expression $z^TMz$, $Mz$ is the transformed vector of $z$.
Therefore the entire expression is the dot product of the vector to its transformed vector.
Hence a positive definite transformation $\biimpl$ dot product of any vector with its transformed one $> 0$.
Similarly for others.
''',

r'''
\proofbydefinition
'''

) }


\todo
\begin{enumerate}[nolistsep]
  \item composition of linear transforms, composition as product of matrices, building matrix as tool
  \item proof of composition of linear transform is a linear transform, algebraically and geometrically
  \item misconceptions: \xcancel{animating vectors} vs \xcancel{animating coordinate frames} don't try to animate (lerp) anything
  \item latest frame vs initial frame
  \item representation of rotation: rot mat, quaternions, axis-angle, eular, roll pitch yaw, gimbal lock
  \item determinant, descriminant whatever
  \item cross product
  \item inverses
  \item column spaces, rank
  \item null spaces
  \item eigen stuff, eigen basis
  \item orthogonal, orthonormal
  \item diagnoal
  \item quaternions
  \item SVD, other easy useful decompositions
\end{enumerate}

\todo
\begin{enumerate}[nolistsep]
  \item multiplication of quaternions is not commutative
  \item rot mat $<-`>$ eular angle $<->$ rpy
  \item what is gimbal lock? not single solution with gimbal lock?
  \item axis-angle $<->$ rotation matrix - eigen basis, null space finding
  \item Code/Visualize/Animate the math
  \item how to tell which system has how many and what type  of solutions? and what is a solution exactly?
  \item sensing: hw1 p1 how is orientation not determinable?
  \item $a^T * b = b^T$ * a iff a, b are vectors
  \item what is determinant of transform matrix with only rotation and translation ? == 1
  \item composition of linear transformations
  \item rotation \& quaternions
\end{enumerate}

\end{document}
