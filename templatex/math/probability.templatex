\documentclass[../main.tex]{subfiles}

\begin{document}
\chapter{probability}

${ add_statement(

'Experiment',

r'''
A list of instructions which when followed produces some outcome.
''',

r'''
Can be used to represent a lot of things food recipies, code, course registrations etc... The meaning of this is not just limited to experiments which involve physics or chemistry. They are just a class of experiments called physical and chemical experiments respectively. There can exist imaginary experiments like (surprise surprise!) adding two numbers in your head, calculating limits etc...
''',

r'''
\proofbydefinition
'''

) }



${ add_statement(

'Deterministic Experiment',

r'''
Let $ O_k $ represent the final outcome when an @experiment@ is repeated k times, an experiment such that $ O_1, O_2, O_3, ... O_n $ are pairwise identical @identity@ $\forall n \in \mathbb{N} $ @natural numbers@ is called a deterministic experiment.
''',

r'''
Can be used to represent experiments like adding two numbers.
''',

r'''
\proofbydefinition
'''

) }

${ add_statement(

'Non-deterministic Experiment',

r'''
Let $ O_k $ represent the final outcome when an @experiment@ is repeated k times, an experiment such that $ \exists (i, j) \st O_i \not\equiv O_j $ @identity@ is called a non-deterministic experiment.
''',

r'''
Note that outcome can remain same for some repetitions of the experiement.
Can be used to represent experiments like rolling a dice.
''',

r'''
\proofbydefinition
'''

) }

${ add_statement(

'Outcome Space',

r'''
The outcome space of an @experiment@ is the @set@ of its all possible outcomes.
''',

r'''
A term to refer to all possible outcomes collectively.
''',

r'''
\proofbydefinition
'''

) }

${ add_statement(

'Event',

r'''
An event $ E $ of an @experiment@ is a @subset@ of @outcome space@. An event is said to have occured $ \biimpl $ $ \exists $ outcome $ \in E $ that occured.
''',

r'''
The number of elements in an event can be 0, 1 or even total number of possible outcomes.
''',

r'''
\proofbydefinition
'''

) }

${ add_statement(

'Mutually Exclusive Events',

r'''
Two @event@s A and B of an @experiment@ are mutually exclusive events $ \biimpl $ $ A \cap B \equiv \phi $ @null set@.
''',

r'''
For example in the experiement of throwing a dice the event of getting an even number and the event of getting an odd number are mutually exclusive events.
Note that they are not independent events, even both words are eerily similar.
Mutually exclusive mean that at max one can occur at a given time.
Independent means both can occur at the same time.
Mutually exclusive events can occur in non-stochastic experiements too.
Independent events can not occur in non-stochastic experiements.
''',

r'''
\proofbydefinition
'''

) }

${ add_statement(

'Event Space',

r'''
The event space of an @experiment@ is the @set@ of all possible @event@s of the experiement.
''',

r'''
A term to refer to all possible events collectively
''',

r'''
\proofbydefinition
'''

) }

${ add_statement(

'Collapsed Experiment',

r'''
A collapsed experiment of an @experiment@ E is a new experiment F where F's @outcome space@ is a @proper subset@ of the E's outcome space.
''',

r'''
Why not also consider a proper superset of the outcome space?
Something like an Expanded Experiement?
Good question.
By definition outcome space is a universal set for the experiment outcomes.
A proper superset of universal set doesn't exist.
''',

r'''
\proofbydefinition
'''

) }


${ add_statement(

'Stochastic Experiment',

r'''
An @experiment@ such that $\forall$ @event@ $ \lambda \in $ @event space@ the limiting value of the ratio
\[
\frac{\text{number-of-times-$\lambda$-occured}}{\text{number-of-repetitions}}
\]
as the number of repetitions tend to infinity, exists, is called a stochastic experiment.
''',

r'''
Useful to build the concept of probability.
Note that by my definition of stochastic experiment
\begin{enumerate}[nolistsep]
    \item All deterministic experiments are stochastic experiments with probability of the only outcome being 1.
    \item Some non-deterministic experiments are stochastic experiments.
\end{enumerate}
\begin{center}
    \begin{tikzpicture}
    \setlength{\parskip}{5mm}
        \draw[fill=blue!60]     (0, 0) -- (90:2.5) arc (90:270:2.5) -- cycle ;
        \draw[]                 (0, 0) circle (2.5) node {Non-deterministic};
        \draw[fill=blue!60]     (0: 5.1) circle (2.5) node {Deterministic};
        \node[anchor=south] at (current bounding box.north) {Stochastic (in blue)};
    \end{tikzpicture}
\end{center}
''',

r'''
\proofbydefinition
'''

) }

${ add_statement(

'Probability',

r'''
The probability of an @event@ $ \lambda $ of a @stochastic experiment@ is the limiting value of the ratio
\[
\frac{\text{number-of-times-$\lambda$-occured}}{\text{number-of-repetitions}}
\]
as the experiment is the repeated infinitely many times. Denoted by $ P(\lambda) $.
''',

r'''
One might easily think that probability gives a sense of power of an event when an experiment is conducted.
Although this is quite easy to misinterpret.
A higher probability does not mean it will occur next.
Even an event with unimaginabily miniscule probability may happen (many times in a row) and an event with very high probability may not occur (many times in a row).
Say an experiement has two outcomes $ \alpha, \beta $ with probabilities 0.999999999999 and 0.000000000001 respectively.
But we can never say with certainity that when an experiment is conducted only $ \alpha $ shall occur.
Nor is the case when experiement is repeated say 100000000000 (any finite number) of times the corresponding ratios shall be 0.999999999999 and 0.000000000001, it can also happen that in all those repetitions $ \alpha $ never occurs.
This subtle nature of probability, that arises from the definition of limit itself, should be digested well.

A good way to remember this is to add meaning to notation.
Consider notation,
\[
    {\color{red} P} {\color{green}  (} {\color{blue} \lambda} {\color{green} )}
\]
Here
\begin{enumerate}[nolistsep]
    \item {\color{red} P} should remind that probability is a limit definition.
    \item {\color{green}  (} {\color{green} )} contains an event(s) therefore an implicit experiment is defined.
    The experiment should be well understood.
    This is the most ignored step while working with probability.
    A simple experiment is to pick any element from a collection and is used very often.
    Note that the phrase `picking at random' is not used, as the word random is not defined yet.
    \item ${\color{blue} \lambda}$ represents an event, which is a fancy name for a set of outcomes of the experiement in context. The event occurs iff any of the outcomes in it occur.
\end{enumerate}
''',

r'''
\proofbydefinition
'''

) }

${ add_statement(

'Properties of probability',

r'''
Given S be the @outcome space@ and A, B be some @event@s of a @stochastic experiment@ E. The following properties hold.
\begin{enumerate}[nolistsep]
  \item $P(A) \ge 0 $
  \item $P(S) \equiv 1 $
  \item $ A \cap B \equiv \phi \impl P(A \cup B) \equiv P(A) + P(B)$ @null set@.
\end{enumerate}

''',

r'''
Some tools to played around with to create new tools.
''',

r'''
\item
\paragraph{1} From the ratio in the definition of probability, wheneven an experiment is conducted the numerator (num. times event E occured until now) $ \ge 1 $ and denominator (num. of repetitions done) $ > 0 $

$ \impl $ the ratio is always $ \ge 0 $.

$ \impl $ the limiting value of the ratio P(A) is also $ \ge 0 $.
\item
\paragraph{2} When the event is identical to outcome space the ratio is identical to one.

$ \impl $ the limiting value of the ratio P(S) is also $ \equiv 1 $.
\item
\paragraph{3} When the intersection b/w two events A and B is a null set, the number of occcurances of event $ A \cup B $ $ \equiv $ number of occurances of A $ + $ number of occurances of B. Therefore the ratios at every repetition and thus limiting values of ratios are equal i.e. $ P(A \cup B) = P(A) + P(B) $.
'''

) }

${ add_statement(

'Independent Events',

r'''
Two @event@s A and B of a @stochastic experiment@ are independent $ \biimpl $ $ P(A \cap B) \equiv P(A) * P(B) $ @probability@.
''',

r'''
Note that they are not mutually exclusive events, even though both words are eerily similar.
Mutually exclusive mean that at max one can occur at a given time.
Independent means both can occur at the same time.
Mutually exclusive events can occur in non-stochastic experiements too.
Independent events can not occur in non-stochastic experiements.
''',

r'''
\proofbydefinition
'''

) }

${ add_statement(

'Conditional Probability',

r'''
Let P(A) denote probability of some @event@ A of original @stochastic experiment@ E.
The conditional probability of an event A given event B, of E, such that B is not a @null set@, is the @probability@ of the event $ A \cap B $ in the @collapsed experiment@ F of E whose @outcome space@ $ \equiv $ B, denoted by P(A$\mid$B) and very specifically it's value is defined as
\[
  P(A \mid B) \equiv \frac{P(A \cap B)}{P(B)}
\]
''',

r'''

Well, minimally it should be, rather than the simple division rule.
\[ P(A \mid B) \equiv \lim_{repetitions\to\infty} \frac{\text{number-of-times-$A \cap B$-occured}}{\text{number-of-repetitions-of-F}} \]
There is no ultimate reason for such a rule.
We can easily construct an experiment which does not obey the such a rule.
For example, consider an experiment with three outcomes each with probability 1/3.
If the experiment is collapsed such that outcome space contains only the second and third outcomes, there is no hard and fast rule that new probabilities become 1/2 as given by the definition.
They can even be 0.4 and 0.6 respectively.
And that is fine.
Such conditional probabilities can be captured by the minimal definition but not by simple division definition.
The simple division rule is a special case.
The reason we choose the simple division rule as the definition is because of its simplicity.
If we ever have a need to capture conditional probability a different way, we can create a new definition.
This is one more big assumption in probability.
Remember this when you use conditional probabilities.

A good way to remember this is to add meaning to notation.
Consider notation,
\[
    {\color{red} P} {\color{green}  (} {\color{blue} \alpha} \mid {\color{magenta} \beta} {\color{green} )}
\]
Here
\begin{enumerate}[nolistsep]
    \item {\color{red} P} should remind that probability is a limit definition.
    \item {\color{green}  (} {\color{green} )} contains an event(s) therefore an implicit experiment is defined.
    The experiment should be well understood.
    This is the most ignored step while working with probability.
    A simple experiment is to pick any element from a collection and is used very often.
    Note that the phrase `picking at random' is not used, as the word random is not defined yet.
    \item ${\color{blue} \alpha}, {\color{magenta} \beta} $ each represents an event, which is a fancy name for a set of outcomes of the experiement in context. The event occurs iff any of the outcomes in it occur.
    \item $\mid$ should remind us that there is an implicit collapsed experiement and the event ${\color{blue} \alpha} \cap {\color{magenta} \beta}$ is the one that is actually considered.
    The collapsed experiment must also be well understood.
    This is another most ignored step while working with probability.
    As it sort of looks like the division operator for real numbers, it should remind us that a simple division rule of conditional probability is used rather than a general limit definition.
\end{enumerate}

By assuming that outcome space collapses to B, we are effectively changing probabilities of some events from original experiement to collapsed experiement.
Because even in collapsed experiement, which has a smaller outcome space, each probability $ \ge $ 0 and probability of the outcome space = 1.
So probabilities are sort of compressed.
The changed probabilities are called conditional probabilities and are defined by whatever rule we follow (here it is the simple division rule).

Some sanity checks for the definition.
\begin{enumerate}[nolistsep]
    \item $ A \cap B $ because even an event of the collapsed experiement must be a subset of its outcome space (here B).
    \item $ \frac{1}{P(B)} $ because it normalizes probabilities such that sum of probabilities of all outcomes = 1.
\end{enumerate}

Observe that $ P(A \mid B) $ is associated with E not F i.e. $ P(A \mid B) $ is conditional probability of event $ A $ given event $ B $ for the original experiment E, not the collapsed experiment F.
''',

r'''
\proofbydefinition
'''

) }


${ add_statement(

'Random Variable',

r'''
A random variable of a @stochastic experiment@ E is a @function@ $ \psi $ mapping from E's @event space@ S to $ [0, 1] $ where

$ \forall \lambda \in S, \psi(\lambda) $ (the image of $ \lambda $ under the function) $ \equiv $ the @probability@ of the event $ \lambda $ and

$ \forall \alpha, \beta \in S \st \beta \not\equiv \phi, \psi(\alpha\mid\beta) \equiv $ the conditional probability of event $ \alpha $ given event $ \beta $.
''',

r'''
A function wrapper around the definitions of experiment, event space, probability.
Note that $ \psi(\alpha \mid \beta) $ is conditional probability of event $ \alpha $ given event $ \beta $ for the original experiment E, not F.
''',

r'''
\proofbydefinition
'''

) }

${ add_statement(

'Total Probability Theorem',

r'''
For a @random variable@ $\psi$ of a @stochastic experiment@ E, let B be some @event@ of E and $\{A_1, A_2, ... A_n\}$ be a @partition@ of @outcome space@ of E, such that none of the $ A_i $ is a @null set@ $ \impl $
\[
  \psi(B) = \sum_{i=1}^{n} \psi(B \mid A_i ) \psi ( A_i )
\]

''',

r'''
Using this theorem we can split the probability of event B into conditional probabilities of B given $ A_i $s and proababilities of $ A_i $s.
''',

r'''
'''

) }

${ add_statement(

'Bayes Theorem',

r'''
For a @random variable@ $\psi$ of a @stochastic experiment@ E, let B be some @event@ of E and $\{A_1, A_2, ... A_n\}$ be a @partition@ of @outcome space@ of E, such that none of the $ A_i $ is a @null set@ $ \impl $
\[
  \psi(A_i \mid B) = \frac{\psi(B \mid A_i ) \psi( A_i )}{\sum_{i=1}^{n} \psi(B \mid A_i ) \psi ( A_i )}
\]

''',

r'''
When you have a world that is constant but cannot be observed accurately at once and you can have evidence which determines something about the world, then you can update what you believe about the world by using this theorem. Videos by \href{https://youtu.be/HZGCoVF3YvM}{3blue1brown} and \href{https://youtu.be/R13BD8qKeTg}{veritasium} provide ideas to build the definition of bayes theorem.
''',

r'''

'''

) }

\begin{enumerate}[nolistsep]
  \item \todo
  \item Cdf and pdf definitions
  \item Expected value definitions
  \item Joint probability definition
  \item Random vectors
  \item baysian networks
  \item How can one say that an experiement is not non-stochastic and/or follows simple division conditional probability rule?
\end{enumerate}
\end{document}
